{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57031efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0] 100\n"
     ]
    }
   ],
   "source": [
    "#有一些严重的Bug被发现：需要做一个bug-fix版本的提交\n",
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_1:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0]\n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0, 1]\n",
    "            \n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_1 = Preprocessing_1()\n",
    "train_list, arch_list_train_1 = processor_1.process_x(train_data)\n",
    "n_feature = len(arch_list_train_1[0])\n",
    "print(arch_list_train_1[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252a41eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] 100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_2:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            '''\n",
    "            if i == 0:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            '''\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1, 0]\n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_2 = Preprocessing_2()\n",
    "train_list, arch_list_train_2 = processor_2.process_x(train_data)\n",
    "n_feature = len(arch_list_train_2[0])\n",
    "print(arch_list_train_2[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9895cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0] 110\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_3:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            '''\n",
    "            if i == 0:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            '''\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                '''\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0]\n",
    "                '''\n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0, 1]\n",
    "            \n",
    "\n",
    "\n",
    "            if i % 3 == 0 and i != 0 and i <= 30:\n",
    "                tmps = ts\n",
    "                if tmps == '11':\n",
    "                    tp = [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '12':\n",
    "                    tp = [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "                \n",
    "                elif tmps == '13':\n",
    "                    tp = [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '21':\n",
    "                    tp = [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '22':\n",
    "                    tp = [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '23':\n",
    "                    tp = [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '31':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "                elif tmps == '32':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "                    \n",
    "                elif tmps == '33':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "            \n",
    "                temp_arch = temp_arch + tp\n",
    "                ts = ''\n",
    "\n",
    "\n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_3 = Preprocessing_3()\n",
    "train_list, arch_list_train_3 = processor_3.process_x(train_data)\n",
    "n_feature = len(arch_list_train_3[0])\n",
    "print(arch_list_train_3[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d5b1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0] 190\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_4:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            '''\n",
    "            if i == 0:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            '''\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                \n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0]\n",
    "                \n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0, 1]\n",
    "            \n",
    "\n",
    "\n",
    "            if i % 3 == 0 and i != 0 and i <= 30:\n",
    "                tmps = ts\n",
    "                if tmps == '11':\n",
    "                    tp = [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '12':\n",
    "                    tp = [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "                \n",
    "                elif tmps == '13':\n",
    "                    tp = [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '21':\n",
    "                    tp = [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '22':\n",
    "                    tp = [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '23':\n",
    "                    tp = [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '31':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "                elif tmps == '32':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "                    \n",
    "                elif tmps == '33':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "            \n",
    "                temp_arch = temp_arch + tp\n",
    "                ts = ''\n",
    "\n",
    "\n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_4 = Preprocessing_4()\n",
    "train_list, arch_list_train_4 = processor_4.process_x(train_data)\n",
    "n_feature = len(arch_list_train_4[0])\n",
    "print(arch_list_train_4[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c82357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] 190\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_5:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            '''\n",
    "            if i == 0:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            '''\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                \n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "                \n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0, 0]\n",
    "            \n",
    "\n",
    "\n",
    "            if i % 3 == 0 and i != 0 and i <= 30:\n",
    "                tmps = ts\n",
    "                if tmps == '11':\n",
    "                    tp = [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '12':\n",
    "                    tp = [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "                \n",
    "                elif tmps == '13':\n",
    "                    tp = [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '21':\n",
    "                    tp = [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '22':\n",
    "                    tp = [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '23':\n",
    "                    tp = [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '31':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "                elif tmps == '32':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "                    \n",
    "                elif tmps == '33':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "            \n",
    "                temp_arch = temp_arch + tp\n",
    "                ts = ''\n",
    "\n",
    "\n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_5 = Preprocessing_5()\n",
    "train_list, arch_list_train_5 = processor_5.process_x(train_data)\n",
    "n_feature = len(arch_list_train_5[0])\n",
    "print(arch_list_train_5[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e66c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import numba as nb\n",
    "import itertools\n",
    "\n",
    "nw = 97\n",
    "weights = [1] * 16\n",
    "n_w = len(weights)\n",
    "w_96 = np.array(weights + [1 for x in range(96 - n_w)])\n",
    "w_97 = np.array(weights + [1 for x in range(97 - n_w)])\n",
    "\n",
    "\n",
    "\n",
    "__all__ = [\"GPNAS\"]\n",
    "\n",
    "\n",
    "def get_correlation(mat1, mat2, task):\n",
    "    mat_diff = np.abs(np.array(mat1) - np.array(mat2))\n",
    "    if np.sum(mat_diff) == 0:\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "    diffs = np.dot(mat_diff, mat_diff)\n",
    "    k2 = 1\n",
    "    k1 = 1 * np.exp(-np.sqrt(diffs) / 22)\n",
    "    #k1 = np.exp(-np.log2(diffs) / 24)\n",
    "    #return k1\n",
    "    return k1 * k2\n",
    "\n",
    "\n",
    "def get_cor_mat_joint(X, X_train, task):\n",
    "    X = np.array(X)\n",
    "    X_train = np.array(X_train)\n",
    "    l_c = X.shape[0]\n",
    "    l_r = X_train.shape[0]\n",
    "    \n",
    "    '''\n",
    "    cor_mat = []\n",
    "\n",
    "    for c_idx in range(l_c):\n",
    "        col = []\n",
    "        c_mat = X[c_idx].copy()\n",
    "\n",
    "        for r_idx in range(l_r):\n",
    "            r_mat = X_train[r_idx].copy()\n",
    "            temp_cor = get_correlation(c_mat, r_mat)\n",
    "            col.append(temp_cor)\n",
    "        cor_mat.append(col)\n",
    "    '''\n",
    "    cor_mat = np.array([get_correlation(c_mat, r_mat, task) for c_mat in X for r_mat in X_train]).reshape((l_c, l_r))\n",
    "\n",
    "    return np.mat(cor_mat)\n",
    "\n",
    "\n",
    "\n",
    "class GPNAS(object):\n",
    "    \"\"\"\n",
    "    GPNAS(Gaussian Process based Neural Architecture Search) is a neural architecture search algorithm.\n",
    "    We model the correlation between architectue and performance from a Bayesian perspective. Specifically, by introducing a novel Gaussian Process based\n",
    "    NAS (GP-NAS) method, the correlations are modeled by the kernel function and mean function. The kernel function is also learnable to enable adaptive modeling for complex\n",
    "    correlations in different search spaces. Furthermore, by in-corporating a mutual information based sampling method, we can theoretically ensure the high-performance\n",
    "    architecture with only a small set of samples. After addressing these problems, training GP-NAS once enables direct performance prediction of any architecture in different\n",
    "    scenarios and may obtain efficient networks for different deployment platforms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c_flag=2, m_flag=2):\n",
    "\n",
    "        #self.hp_mat = 0.0000001\n",
    "        #self.hp_cov = 0.01\n",
    "        self.hp_mat = 0.01\n",
    "        self.hp_cov = 0.05\n",
    "        self.cov_w = None\n",
    "        self.w = None\n",
    "        self.c_flag = c_flag\n",
    "        self.m_flag = m_flag\n",
    "    \n",
    "    def set_task(self, task):\n",
    "        self.task = task\n",
    "        \n",
    "    def set_weight(self, weight):\n",
    "        self.weight = weight\n",
    "\n",
    "    \n",
    "    def _get_corelation(self, mat1, mat2):\n",
    "        \"\"\"\n",
    "        give two typical kernel function\n",
    "\n",
    "        Auto kernel hyperparameters estimation to be updated\n",
    "        \"\"\"\n",
    "        '''\n",
    "        mat_diff = abs(mat1 - mat2)\n",
    "        \n",
    "        \n",
    "        mat_diff = mat1 - mat2\n",
    "        ker = np.zeros(int(len(mat1) / 4))\n",
    "\n",
    "        for i in range(int(len(mat1) / 4)):\n",
    "            part = np.array(mat_diff[i*4:(i+1) * 4])\n",
    "            diffs = np.where(part!= 0)[0]\n",
    "            if len(diffs) != 0:\n",
    "                d = diffs[1] - diffs[0]\n",
    "                ker[i] = d\n",
    "                \n",
    "        mat_diff = ker\n",
    "        \n",
    "                \n",
    "        if self.c_flag == 1:\n",
    "\n",
    "            return 0.5 * np.exp(-np.dot(mat_diff, mat_diff) / 16)\n",
    "\n",
    "        elif self.c_flag == 2:\n",
    "\n",
    "            return 1 * np.exp(-np.sqrt(np.dot(mat_diff, mat_diff)) / 12)\n",
    "        '''\n",
    "        return get_correlation(mat1, mat2, self.task)\n",
    "\n",
    "    def _preprocess_X(self, X):\n",
    "        \"\"\"\n",
    "        preprocess of input feature/ tokens of architecture\n",
    "        more complicated preprocess can be added such as nonlineaer transformation\n",
    "        \"\"\"\n",
    "\n",
    "        X = X.tolist()\n",
    "        p_X = copy.deepcopy(X)\n",
    "\n",
    "        for feature in p_X:\n",
    "            feature.append(1)\n",
    "\n",
    "        return p_X\n",
    "\n",
    "    def _get_cor_mat(self, X):\n",
    "        \"\"\"\n",
    "        get kernel matrix\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        l = X.shape[0]\n",
    "        cor_mat = []\n",
    "\n",
    "        for c_idx in range(l):\n",
    "            col = []\n",
    "            c_mat = X[c_idx].copy()\n",
    "\n",
    "            for r_idx in range(l):\n",
    "                r_mat = X[r_idx].copy()\n",
    "                temp_cor = self._get_corelation(c_mat, r_mat)\n",
    "                col.append(temp_cor)\n",
    "            cor_mat.append(col)\n",
    "\n",
    "        return np.mat(cor_mat)\n",
    "\n",
    "    def _get_cor_mat_joint(self, X, X_train):\n",
    "        \"\"\"\n",
    "        get kernel matrix\n",
    "        \"\"\"\n",
    "        '''\n",
    "        X = np.array(X)\n",
    "        X_train = np.array(X_train)\n",
    "        l_c = X.shape[0]\n",
    "        l_r = X_train.shape[0]\n",
    "        cor_mat = []\n",
    "\n",
    "        for c_idx in range(l_c):\n",
    "            col = []\n",
    "            c_mat = X[c_idx].copy()\n",
    "\n",
    "            for r_idx in range(l_r):\n",
    "                r_mat = X_train[r_idx].copy()\n",
    "                temp_cor = self._get_corelation(c_mat, r_mat)\n",
    "                col.append(temp_cor)\n",
    "            cor_mat.append(col)\n",
    "        '''\n",
    "        res = get_cor_mat_joint(X, X_train, self.task)\n",
    "\n",
    "        return np.mat(res)\n",
    "\n",
    "    def get_predict(self, X):\n",
    "        \"\"\"\n",
    "        get the prediction of network architecture X\n",
    "        \"\"\"\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        #print(X.shape)\n",
    "        #print(X[0])\n",
    "\n",
    "        return X * self.w\n",
    "\n",
    "    def get_predict_jiont(self, X, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        get the prediction of network architecture X based on X_train and Y_train\n",
    "        \"\"\"\n",
    "        #X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        X_train = np.mat(X_train)\n",
    "        Y_train = np.mat(Y_train)\n",
    "        m_X = self.get_predict(X)\n",
    "        m_X_train = self.get_predict(X_train)\n",
    "        mat_train = self._get_cor_mat(X_train)\n",
    "        mat_joint = self._get_cor_mat_joint(X, X_train)\n",
    "\n",
    "        return m_X + mat_joint * np.linalg.inv(mat_train + self.hp_mat * np.eye(\n",
    "            X_train.shape[0])) * (Y_train.T - m_X_train)\n",
    "\n",
    "    def get_initial_mean(self, X, Y):\n",
    "        \"\"\"\n",
    "        get initial mean of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        Y = np.mat(Y)\n",
    "        A = np.linalg.inv(X.T * X + self.hp_mat * np.eye(X.shape[\n",
    "            1]))\n",
    "        B = X.T\n",
    "        C = Y.T\n",
    "        print(f'A,B,C shape is {A.shape}, {B.shape}, {C.shape}')\n",
    "        self.w = np.linalg.inv(X.T * X + self.hp_mat * np.eye(X.shape[\n",
    "            1])) * X.T * Y.T\n",
    "\n",
    "        return self.w \n",
    "\n",
    "    def get_initial_cov(self, X):\n",
    "        \"\"\"\n",
    "        get initial coviarnce matrix of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        self.cov_w = self.hp_cov * np.eye(X.shape[1])\n",
    "\n",
    "        return self.cov_w\n",
    "\n",
    "    def get_posterior_mean(self, X, Y):\n",
    "        \"\"\"\n",
    "        get posterior mean of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)           #特征抽取\n",
    "        X = np.mat(X)                       #X的矩阵化\n",
    "        Y = np.mat(Y)                       #Y的矩阵化\n",
    "        cov_mat = self._get_cor_mat(X)      #获得一个叫做cov_mat的东西\n",
    "        if self.m_flag == 1:\n",
    "            self.w = self.w + self.cov_w * X.T * np.linalg.inv(\n",
    "                np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "                 + X * self.cov_w * X.T + self.hp_mat * np.eye(X.shape[0]))* (Y.T - X * self.w)\n",
    "        else:\n",
    "            a1 = np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "            a2 = np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                        1]))\n",
    "            #print(f'the shape of a1 and a2 is {a1.shape}, {a2.shape}')\n",
    "            tmp = X.T * a1 * X\n",
    "            #print(f'Xshape is {X.shape}, XT shape is {X.T.shape},tmp shape is {tmp.shape}')\n",
    "            A = np.linalg.inv(X.T * a1 * X + a2 + self.hp_mat * np.eye(X.shape[1]))\n",
    "            '''\n",
    "            A = np.linalg.inv(X.T * np.linalg.inv(\n",
    "                cov_mat + self.hp_mat * np.eye(X.shape[0])) * X\n",
    "                + np.linalg.inv(\n",
    "                    self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                        1])) + self.hp_mat * np.eye(X.shape[1]))\n",
    "            '''\n",
    "            b1 = np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "            b2 = np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[1]))\n",
    "            #print(f'b1 shape is {b1.shape}, b2 shape is {b2.shape}')\n",
    "            B = (X.T * b1 * Y.T + b2 * self.w)\n",
    "            #print(f'the shape of A and B is {A.shape}, {B.shape}')\n",
    "            self.w = A * B\n",
    "\n",
    "        return self.w\n",
    "\n",
    "    def get_posterior_cov(self, X, Y):\n",
    "        \"\"\"\n",
    "        get posterior coviarnce matrix of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        Y = np.mat(Y)\n",
    "        cov_mat = self._get_cor_mat(X)\n",
    "        self.cov_mat = np.linalg.inv(\n",
    "            np.linalg.inv(X.T * cov_mat * X + self.hp_mat * np.eye(X.shape[1]))\n",
    "            + np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                1])) + self.hp_mat * np.eye(X.shape[1]))\n",
    "\n",
    "        return self.cov_mat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "804253d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4194676",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0402计划\n",
    "## y的处理: 从rank变成分数\n",
    "## 方式：正太化\n",
    "class Label_Transformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_rankdict(self, ranks):\n",
    "        np.random.seed(0)\n",
    "        n = len(ranks)\n",
    "        scores = np.random.normal(0, 1, n)\n",
    "        #scores = np.random.standard_cauchy(n)\n",
    "        temp = scores.argsort()\n",
    "        ranks = np.empty_like(temp)\n",
    "        ranks[temp] = np.arange(len(scores))\n",
    "        ranks = (n - 1) - ranks\n",
    "        rankdict = {}\n",
    "        for i in range(n):\n",
    "            rankdict[ranks[i]] = scores[i]\n",
    "        return rankdict\n",
    "    \n",
    "    def rank_to_score(self, rank_dict, ranks):\n",
    "        res = np.array([rank_dict[x] for x in ranks])\n",
    "        return res\n",
    "    \n",
    "    def rank_to_score_direct(self, ranks):\n",
    "        rank_dict = self.get_rankdict(ranks)\n",
    "        score = self.rank_to_score(rank_dict, ranks)\n",
    "        return score\n",
    "        \n",
    "    \n",
    "    def score_to_rank(self, scores):\n",
    "        scores = np.array(scores)\n",
    "        temp = scores.argsort()\n",
    "        rr = np.empty_like(temp)\n",
    "        rr[temp] = np.arange(len(scores))\n",
    "        rr = rr.max() - rr\n",
    "        return rr\n",
    "            \n",
    "        \n",
    "        \n",
    "label_transformer = Label_Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c908b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "\n",
    "gp_list_1 = []\n",
    "gp_list_2 = []\n",
    "gp_list_3 = []\n",
    "gp_list_4 = []\n",
    "gp_list_5 = []\n",
    "\n",
    "\n",
    "\n",
    "Y_score = {}\n",
    "\n",
    "knn_list = []\n",
    "\n",
    "\n",
    "for i in range(len(train_list[:])):\n",
    "    gp_list_1.append(GPNAS(2,2))\n",
    "    gp_list_2.append(GPNAS(2,2))\n",
    "    gp_list_3.append(GPNAS(2,2))\n",
    "    gp_list_4.append(GPNAS(2,2))\n",
    "    gp_list_5.append(GPNAS(2,2))\n",
    "    knn_list.append(KNeighborsRegressor(n_neighbors=20))\n",
    "\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train_1), np.array(train_list[i])\n",
    "    Y_all_k = label_transformer.rank_to_score_direct(Y_all_k)\n",
    "    Y_score[i] = Y_all_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42863d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (111, 111), (111, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 1/8 [00:08<00:56,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (111, 111), (111, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:15<00:46,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (111, 111), (111, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [00:23<00:38,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (111, 111), (111, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [00:31<00:31,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (111, 111), (111, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [00:39<00:23,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (111, 111), (111, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [00:46<00:15,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (111, 111), (111, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [00:54<00:07,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (101, 101), (101, 200), (200, 1)\n",
      "A,B,C shape is (111, 111), (111, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n",
      "A,B,C shape is (191, 191), (191, 200), (200, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:02<00:00,  7.82s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(8)):\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train_1), np.array(train_list[i])\n",
    "    Y_all_k = Y_score[i]\n",
    "    \n",
    "    X_train_k, X_test_k, Y_train_k, Y_test_k = train_test_split(X_all_k, Y_all_k, test_size=0.2, random_state=4)\n",
    "\n",
    "    gp_list_1[i].get_initial_mean(X_train_k[0::2],Y_train_k[0::2])\n",
    "    init_cov = gp_list_1[i].get_initial_cov(X_train_k)\n",
    "    gp_list_1[i].set_task(i) \n",
    "    gp_list_1[i].get_posterior_mean(X_train_k[1::2],Y_train_k[1::2]) \n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train_2), np.array(train_list[i])\n",
    "    Y_all_k = Y_score[i]\n",
    "    \n",
    "    X_train_k, X_test_k, Y_train_k, Y_test_k = train_test_split(X_all_k, Y_all_k, test_size=0.2, random_state=4)\n",
    "\n",
    "    gp_list_2[i].get_initial_mean(X_train_k[0::2],Y_train_k[0::2])\n",
    "    init_cov = gp_list_2[i].get_initial_cov(X_train_k)\n",
    "    gp_list_2[i].set_task(i) \n",
    "    gp_list_2[i].get_posterior_mean(X_train_k[1::2],Y_train_k[1::2]) \n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train_3), np.array(train_list[i])\n",
    "    Y_all_k = Y_score[i]\n",
    "    \n",
    "    X_train_k, X_test_k, Y_train_k, Y_test_k = train_test_split(X_all_k, Y_all_k, test_size=0.2, random_state=4)\n",
    "\n",
    "    gp_list_3[i].get_initial_mean(X_train_k[0::2],Y_train_k[0::2])\n",
    "    init_cov = gp_list_3[i].get_initial_cov(X_train_k)\n",
    "    gp_list_3[i].set_task(i) \n",
    "    gp_list_3[i].get_posterior_mean(X_train_k[1::2],Y_train_k[1::2]) \n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train_4), np.array(train_list[i])\n",
    "    Y_all_k = Y_score[i]\n",
    "    \n",
    "    X_train_k, X_test_k, Y_train_k, Y_test_k = train_test_split(X_all_k, Y_all_k, test_size=0.2, random_state=4)\n",
    "\n",
    "    gp_list_4[i].get_initial_mean(X_train_k[0::2],Y_train_k[0::2])\n",
    "    init_cov = gp_list_4[i].get_initial_cov(X_train_k)\n",
    "    gp_list_4[i].set_task(i) \n",
    "    gp_list_4[i].get_posterior_mean(X_train_k[1::2],Y_train_k[1::2]) \n",
    "\n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train_5), np.array(train_list[i])\n",
    "    Y_all_k = Y_score[i]\n",
    "    \n",
    "    X_train_k, X_test_k, Y_train_k, Y_test_k = train_test_split(X_all_k, Y_all_k, test_size=0.2, random_state=4)\n",
    "\n",
    "    gp_list_5[i].get_initial_mean(X_train_k[0::2],Y_train_k[0::2])\n",
    "    init_cov = gp_list_5[i].get_initial_cov(X_train_k)\n",
    "    gp_list_5[i].set_task(i) \n",
    "    gp_list_5[i].get_posterior_mean(X_train_k[1::2],Y_train_k[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc59ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#from pyproj import Transformer\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2c5fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "\n",
    "gp_list_1 = []\n",
    "gp_list_2 = []\n",
    "gp_list_3 = []\n",
    "gp_list_4 = []\n",
    "gp_list_5 = []\n",
    "knn_list = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(train_list[:])):\n",
    "    gp_list_1.append(GPNAS(2,2))\n",
    "    gp_list_2.append(GPNAS(2,2))\n",
    "    gp_list_3.append(GPNAS(2,2))\n",
    "    gp_list_4.append(GPNAS(2,2))\n",
    "    gp_list_5.append(GPNAS(2,2))\n",
    "    knn_list.append(KNeighborsRegressor(n_neighbors=10))\n",
    "\n",
    "\n",
    "train_num = 450\n",
    "Y_score = {}\n",
    "Y_pred_2 = []\n",
    "for i in range(8):\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train_1), np.array(train_list[i])\n",
    "    Y_all_k = label_transformer.rank_to_score_direct(Y_all_k)\n",
    "    Y_score[i] = Y_all_k\n",
    "\n",
    "\n",
    "def train_model(gp_list, index):\n",
    "\n",
    "    for i in tqdm(range(8)):\n",
    "        if index == 1:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_1), np.array(train_list[i])\n",
    "        elif index == 2:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_2), np.array(train_list[i])\n",
    "        elif index == 3:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_3), np.array(train_list[i])\n",
    "        elif index == 4:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_4), np.array(train_list[i])\n",
    "        elif index == 5:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_5), np.array(train_list[i])\n",
    "            \n",
    "        Y_all_k = Y_score[i]\n",
    "        \n",
    "        \n",
    "        #weight = get_weight(**weight_list[i]['params'])\n",
    "        #gp_list[i].set_task(i)\n",
    "        #gp_list[i].set_weight(weight)\n",
    "        \n",
    "        \n",
    "        gp_list[i].get_initial_mean(X_all_k[0::2],Y_all_k[0::2])\n",
    "        init_cov = gp_list[i].get_initial_cov(X_all_k)\n",
    "        gp_list[i].set_task(i)\n",
    "        gp_list[i].get_posterior_mean(X_all_k,Y_all_k) \n",
    "        if index == 1:\n",
    "            knn_list[i].fit(X_all_k, Y_all_k)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b1afda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 1/8 [00:07<00:52,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:14<00:44,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [00:22<00:36,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [00:30<00:31,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [00:38<00:23,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [00:45<00:15,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [00:52<00:07,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:59<00:00,  7.45s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 1/8 [00:07<00:51,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:14<00:43,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [00:22<00:36,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [00:29<00:29,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [00:36<00:21,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [00:43<00:14,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [00:51<00:07,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (101, 101), (101, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:58<00:00,  7.33s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (111, 111), (111, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 1/8 [00:07<00:52,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (111, 111), (111, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:14<00:44,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (111, 111), (111, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [00:22<00:37,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (111, 111), (111, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [00:29<00:29,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (111, 111), (111, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [00:37<00:22,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (111, 111), (111, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [00:45<00:15,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (111, 111), (111, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [00:52<00:07,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (111, 111), (111, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:00<00:00,  7.52s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 1/8 [00:08<00:56,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:16<00:50,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [00:24<00:41,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [00:33<00:33,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [00:44<00:27,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [00:55<00:19,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [01:05<00:09,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:16<00:00,  9.52s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 1/8 [00:10<01:10, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:20<01:01, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [00:27<00:44,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [00:34<00:32,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [00:42<00:23,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [00:49<00:15,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [00:55<00:07,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C shape is (191, 191), (191, 250), (250, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:02<00:00,  7.83s/it]\n"
     ]
    }
   ],
   "source": [
    "train_model(gp_list_1, 1 )\n",
    "train_model(gp_list_2, 2 )\n",
    "train_model(gp_list_3, 3 )\n",
    "train_model(gp_list_4, 4 )\n",
    "train_model(gp_list_5, 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d9f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ENSEMBLE模型搭建\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import numba as nb\n",
    "import itertools\n",
    "\n",
    "\n",
    "class GPNAS_ensemble(object):\n",
    "\n",
    "    def __init__(self, c_flag, m_flag, gp1, gp2, gp3, gp4, gp5, model_knn, base_rate):\n",
    "\n",
    "        self.hp_mat = 0.0001\n",
    "        self.hp_cov = 0.01\n",
    "        self.cov_w = None\n",
    "        self.w = None\n",
    "        self.c_flag = c_flag\n",
    "        self.m_flag = m_flag\n",
    "        self.gp_1 = gp1\n",
    "        self.gp_2 = gp2\n",
    "        self.gp_3 = gp3\n",
    "        self.gp_4 = gp4\n",
    "        self.gp_5 = gp5\n",
    "        self.knn_model = model_knn\n",
    "        self.base_rate = base_rate\n",
    "        self.default_mode = 1\n",
    "    \n",
    "    def set_task(self, task):\n",
    "        self.task = task\n",
    "\n",
    "    def set_weight(self, weight):\n",
    "        self.weight = weight\n",
    "\n",
    "    \n",
    "    def _get_corelation(self, mat1, mat2):\n",
    "        return get_correlation(mat1, mat2, self.task)\n",
    "\n",
    "    def _preprocess_X(self, X):\n",
    "\n",
    "        X = X.tolist()\n",
    "        p_X = copy.deepcopy(X)\n",
    "\n",
    "        for feature in p_X:\n",
    "            feature.append(1)\n",
    "\n",
    "        return p_X\n",
    "\n",
    "    def _get_cor_mat(self, X):\n",
    "\n",
    "        X = np.array(X)\n",
    "        l = X.shape[0]\n",
    "        cor_mat = []\n",
    "\n",
    "        for c_idx in range(l):\n",
    "            col = []\n",
    "            c_mat = X[c_idx].copy()\n",
    "\n",
    "            for r_idx in range(l):\n",
    "                r_mat = X[r_idx].copy()\n",
    "                temp_cor = self._get_corelation(c_mat, r_mat)\n",
    "                col.append(temp_cor)\n",
    "            cor_mat.append(col)\n",
    "\n",
    "        return np.mat(cor_mat)\n",
    "\n",
    "    def _get_cor_mat_joint(self, X, X_train):\n",
    "\n",
    "        res = get_cor_mat_joint(X, X_train, self.task)\n",
    "\n",
    "        return np.mat(res)\n",
    "\n",
    "    def get_predict(self, X1, X2, X3, X4, X5):\n",
    "        \"\"\"\n",
    "        get the prediction of network architecture X\n",
    "        \"\"\"\n",
    "        #X1 = self._preprocess_X(X1)\n",
    "        #X2 = self._preprocess_X(X2)\n",
    "        #X1 = np.mat(X1)\n",
    "        #X2 = np.mat(X2)\n",
    "        res1 = self.gp_1.get_predict(X1)\n",
    "        res2 = self.gp_2.get_predict(X2)\n",
    "        res3 = self.gp_3.get_predict(X3)\n",
    "        res4 = self.gp_4.get_predict(X4)\n",
    "        res5 = self.gp_5.get_predict(X5)\n",
    "        res6 = self.knn_model.predict(X1).reshape(-1,1)\n",
    "        #print(res1.shape, res2.shape, res3.shape)\n",
    "        res = self.base_rate[0] * res1 + self.base_rate[1] * res2 + self.base_rate[2] * res3 + self.base_rate[3] * res4 +self.base_rate[4] * res5 +self.base_rate[5] * res6 \n",
    "        return res\n",
    "\n",
    "    def get_predict_jiont(self, X1, X2, X3, X4, X5, X_train_1, X_train_2, X_train_3, X_train_4, X_train_5, Y_train):\n",
    "        \"\"\"\n",
    "        get the prediction of network architecture X based on X_train and Y_train\n",
    "        \"\"\"\n",
    "        #X = self._preprocess_X(X)\n",
    "        if self.default_mode == 1:\n",
    "            X1 = np.mat(X1)\n",
    "            X_train_1 = np.mat(X_train_1)\n",
    "            Y_train = np.mat(Y_train)\n",
    "            #print(X1.shape)\n",
    "            m_X = self.get_predict(X1, X2, X3, X4, X5)\n",
    "            m_X_train = self.get_predict(X_train_1, X_train_2, X_train_3, X_train_4, X_train_5)\n",
    "            mat_train = self._get_cor_mat(X_train_1)\n",
    "            mat_joint = self._get_cor_mat_joint(X1, X_train_1)\n",
    "\n",
    "            return m_X + mat_joint * np.linalg.inv(mat_train + self.hp_mat * np.eye(\n",
    "                X_train_1.shape[0])) * (Y_train.T - m_X_train)\n",
    "        \n",
    "        elif self.default_mode == 2:\n",
    "            X2 = np.mat(X2)\n",
    "            X_train_2 = np.mat(X_train_2)\n",
    "            Y_train = np.mat(Y_train)\n",
    "            #print(X1.shape)\n",
    "            m_X = self.get_predict(X1, X2, X3, X4, X5)\n",
    "            m_X_train = self.get_predict(X_train_1, X_train_2, X_train_3, X_train_4, X_train_5)\n",
    "            mat_train = self._get_cor_mat(X_train_2)\n",
    "            mat_joint = self._get_cor_mat_joint(X2, X_train_2)\n",
    "\n",
    "            return m_X + mat_joint * np.linalg.inv(mat_train + self.hp_mat * np.eye(\n",
    "                X_train_2.shape[0])) * (Y_train.T - m_X_train)\n",
    "        \n",
    "\n",
    "    def get_initial_mean(self, X, Y):\n",
    "        \"\"\"\n",
    "        get initial mean of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        Y = np.mat(Y)\n",
    "        A = np.linalg.inv(X.T * X + self.hp_mat * np.eye(X.shape[\n",
    "            1]))\n",
    "        B = X.T\n",
    "        C = Y.T\n",
    "        #print(f'A,B,C shape is {A.shape}, {B.shape}, {C.shape}')\n",
    "        self.w = np.linalg.inv(X.T * X + self.hp_mat * np.eye(X.shape[\n",
    "            1])) * X.T * Y.T\n",
    "\n",
    "        return self.w\n",
    "\n",
    "    def get_initial_cov(self, X):\n",
    "        \"\"\"\n",
    "        get initial coviarnce matrix of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        self.cov_w = self.hp_cov * np.eye(X.shape[1])\n",
    "\n",
    "        return self.cov_w\n",
    "\n",
    "    def get_posterior_mean(self, X, Y):\n",
    "        \"\"\"\n",
    "        get posterior mean of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)           #特征抽取\n",
    "        X = np.mat(X)                       #X的矩阵化\n",
    "        Y = np.mat(Y)                       #Y的矩阵化\n",
    "        cov_mat = self._get_cor_mat(X)      #获得一个叫做cov_mat的东西\n",
    "        if self.m_flag == 1:\n",
    "            self.w = self.w + self.cov_w * X.T * np.linalg.inv(\n",
    "                np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "                 + X * self.cov_w * X.T + self.hp_mat * np.eye(X.shape[0]))* (Y.T - X * self.w)\n",
    "        else:\n",
    "            a1 = np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "            a2 = np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                        1]))\n",
    "            #print(f'the shape of a1 and a2 is {a1.shape}, {a2.shape}')\n",
    "            tmp = X.T * a1 * X\n",
    "            #print(f'Xshape is {X.shape}, XT shape is {X.T.shape},tmp shape is {tmp.shape}')\n",
    "            A = np.linalg.inv(X.T * a1 * X + a2 + self.hp_mat * np.eye(X.shape[1]))\n",
    "            b1 = np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "            b2 = np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[1]))\n",
    "            #print(f'b1 shape is {b1.shape}, b2 shape is {b2.shape}')\n",
    "            B = (X.T * b1 * Y.T + b2 * self.w)\n",
    "            #print(f'the shape of A and B is {A.shape}, {B.shape}')\n",
    "            self.w = A * B\n",
    "\n",
    "        return self.w\n",
    "\n",
    "    def get_posterior_cov(self, X, Y):\n",
    "        \"\"\"\n",
    "        get posterior coviarnce matrix of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        Y = np.mat(Y)\n",
    "        cov_mat = self._get_cor_mat(X)\n",
    "        self.cov_mat = np.linalg.inv(\n",
    "            np.linalg.inv(X.T * cov_mat * X + self.hp_mat * np.eye(X.shape[1]))\n",
    "            + np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                1])) + self.hp_mat * np.eye(X.shape[1]))\n",
    "\n",
    "        return self.cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10942abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:06<00:43,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendalltau: KendalltauResult(correlation=0.2836363636363637, pvalue=2.8987777546046695e-05)\n",
      "mae: 0.7973469898444254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:12<00:36,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendalltau: KendalltauResult(correlation=0.8795959595959597, pvalue=1.8894282360887158e-38)\n",
      "mae: 0.17986678362731326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [00:18<00:31,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendalltau: KendalltauResult(correlation=0.9030303030303031, pvalue=1.9665329139005654e-40)\n",
      "mae: 0.11359275637830717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [00:25<00:25,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendalltau: KendalltauResult(correlation=0.9551515151515152, pvalue=5.0028771917394934e-45)\n",
      "mae: 0.06325590007319576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [00:31<00:19,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendalltau: KendalltauResult(correlation=0.8917171717171719, pvalue=1.8082871733326466e-39)\n",
      "mae: 0.11833702352448308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [00:38<00:12,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendalltau: KendalltauResult(correlation=0.6795959595959598, pvalue=1.2655408665316383e-23)\n",
      "mae: 0.3546879758503034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [00:44<00:06,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendalltau: KendalltauResult(correlation=0.9313131313131315, pvalue=6.795536331065963e-43)\n",
      "mae: 0.1081319031574791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:50<00:00,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendalltau: KendalltauResult(correlation=0.7737373737373738, pvalue=3.894273795990689e-30)\n",
      "mae: 0.2796663707459852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 训练Ensemble模型\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "gp_ensembles = []\n",
    "'''\n",
    "gp_list_1 = []\n",
    "gp_list_2 = []\n",
    "knn_list = []\n",
    "'''\n",
    "for i in range(8):\n",
    "    gp1 = gp_list_1[i]\n",
    "    gp2 = gp_list_2[i]\n",
    "    gp3 = gp_list_3[i]\n",
    "    gp4 = gp_list_4[i]\n",
    "    gp5 = gp_list_5[i]\n",
    "    \n",
    "\n",
    "    model_knn = knn_list[i]\n",
    "    if i == 0:\n",
    "        base_rate = [0.3, 0.3, 0, 0, 0, 0.4]\n",
    "    elif i == 5:\n",
    "        base_rate = [0.3,0.5,0.0666,0.0666,0.0666, 0]\n",
    "    else:\n",
    "        base_rate = [0.55,0.3,0.05, 0.05, 0.05, 0]\n",
    "        \n",
    "    gp_ensembles.append(GPNAS_ensemble(2, 2, gp1, gp2, gp3, gp4, gp5, model_knn, base_rate))\n",
    "    gp_ensembles[i].default_mode = 1\n",
    "    \n",
    "for i in tqdm(range(8)):\n",
    "    #默认是1\n",
    "    X_all_k_1, X_all_k_2  = np.array(arch_list_train_1), np.array(arch_list_train_2)\n",
    "    X_all_k_3, X_all_k_4  = np.array(arch_list_train_3), np.array(arch_list_train_4)\n",
    "    X_all_k_5  = np.array(arch_list_train_5)\n",
    "    Y_all_k = Y_score[i]\n",
    "    X_train_k_1, X_test_k_1, Y_train_k_1, Y_test_k_1 = train_test_split(X_all_k_1, Y_all_k, test_size=0.2, random_state=4)\n",
    "    X_train_k_2, X_test_k_2, Y_train_k_2, Y_test_k_2 = train_test_split(X_all_k_2, Y_all_k, test_size=0.2, random_state=4)\n",
    "    X_train_k_3, X_test_k_3, Y_train_k_3, Y_test_k_3 = train_test_split(X_all_k_3, Y_all_k, test_size=0.2, random_state=4)\n",
    "    X_train_k_4, X_test_k_4, Y_train_k_4, Y_test_k_4 = train_test_split(X_all_k_4, Y_all_k, test_size=0.2, random_state=4)\n",
    "    X_train_k_5, X_test_k_5, Y_train_k_5, Y_test_k_5 = train_test_split(X_all_k_5, Y_all_k, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "\n",
    "    gp_ensembles[i].task = 0\n",
    "    gp_ensembles[i].weight = 0\n",
    "    \n",
    "    X_all_k_1, Y_all_k  = np.array(arch_list_train_1), np.array(train_list[i])\n",
    "    Y_all_k = Y_score[i]\n",
    "    X_train_k, X_test_k, Y_train_k, Y_test_k = train_test_split(X_all_k, Y_all_k, test_size=0.2, random_state=4)\n",
    "    \n",
    "    gp_ensembles[i].get_initial_mean(X_train_k_1[0::2],Y_train_k[0::2])\n",
    "    init_cov = gp_ensembles[i].get_initial_cov(X_train_k_1)\n",
    "    gp_ensembles[i].get_posterior_mean(X_train_k_1[1::2],Y_train_k[1::2]) \n",
    "    \n",
    "\n",
    "    \n",
    "    y_predict = gp_ensembles[i].get_predict_jiont(X_test_k_1, X_test_k_2, X_test_k_3, X_test_k_4, X_test_k_5,\n",
    "                                                  X_train_k_1[::1], X_train_k_2[::1],X_train_k_3[::1], X_train_k_4[::1], X_train_k_5[::1],\n",
    "                                             Y_train_k[::1])\n",
    "                                        \n",
    "\n",
    "    print('Kendalltau:',scipy.stats.stats.kendalltau( y_predict,Y_test_k))\n",
    "    print('mae:', mean_absolute_error(y_predict,Y_test_k))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28e6a069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cplfw_rank': 0,\n",
       " 'market1501_rank': 0,\n",
       " 'dukemtmc_rank': 0,\n",
       " 'msmt17_rank': 0,\n",
       " 'veri_rank': 0,\n",
       " 'vehicleid_rank': 0,\n",
       " 'veriwild_rank': 0,\n",
       " 'sop_rank': 0,\n",
       " 'arch': 'j121221121221221311331321121221000000'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#试一下结果吧\n",
    "with open('CVPR_2022_NAS_Track2_test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "test_data['arch99997']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee605ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "[0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "test_arch_list_1 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_1.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_1.append(test_arch)\n",
    "print(test_arch_list_1[99499])\n",
    "\n",
    "test_arch_list_2 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_2.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_2.append(test_arch)\n",
    "print(test_arch_list_2[99499])\n",
    "\n",
    "test_arch_list_3 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_3.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_3.append(test_arch)\n",
    "print(test_arch_list_3[99499])\n",
    "\n",
    "test_arch_list_4 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_4.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_4.append(test_arch)\n",
    "print(test_arch_list_4[99499])\n",
    "\n",
    "test_arch_list_5 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_5.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_5.append(test_arch)\n",
    "print(test_arch_list_5[99499])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "494a5ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict the rank of: 6\n"
     ]
    }
   ],
   "source": [
    "## Try only task 1\n",
    "name_list = ['veriwild_rank']\n",
    "my_reses = []\n",
    "\n",
    "rank_all = []\n",
    "for task in [6]:\n",
    "    print('Predict the rank of:', task)\n",
    "    Y = Y_score[task]\n",
    "    my_res = gp_ensembles[task].get_predict_jiont(np.array(test_arch_list_1),\n",
    "                                                 np.array(test_arch_list_2),\n",
    "                                                  np.array(test_arch_list_3),\n",
    "                                                  np.array(test_arch_list_4),\n",
    "                                                  np.array(test_arch_list_5),\n",
    "                                                 np.array(arch_list_train_1),\n",
    "                                                 np.array(arch_list_train_2),\n",
    "                                                  np.array(arch_list_train_3),\n",
    "                                                  np.array(arch_list_train_4),\n",
    "                                                  np.array(arch_list_train_5),\n",
    "                                                  Y)\n",
    "    my_reses.append(my_res)\n",
    "    rank_all.append(np.mat(label_transformer.score_to_rank(np.array(my_res.ravel())[0]).reshape(-1,1)))\n",
    "    # fast mode\n",
    "    #rank_all.append(gp_list[task].get_predict(np.array(test_arch_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3e44691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to save results!\n"
     ]
    }
   ],
   "source": [
    "for idx,key in enumerate(test_data.keys()):\n",
    "    #test_data[key]['cplfw_rank'] = int(rank_all[0][idx][0])\n",
    "    #test_data[key]['market1501_rank'] = int(rank_all[1][idx][0])\n",
    "    #test_data[key]['dukemtmc_rank'] = int(rank_all[2][idx][0])\n",
    "    #test_data[key]['msmt17_rank'] = int(rank_all[3][idx][0])\n",
    "    #test_data[key]['veri_rank'] = int(rank_all[4][idx][0])\n",
    "    #test_data[key]['vehicleid_rank'] = int(rank_all[5][idx][0])\n",
    "    test_data[key]['veriwild_rank'] = int(rank_all[0][idx][0])\n",
    "    #test_data[key]['sop_rank'] = int(rank_all[7][idx][0])\n",
    "print('Ready to save results!')\n",
    "with open('CVPR_2022_NAS_Track2_submit_task6_0510version.json', 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2df76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
