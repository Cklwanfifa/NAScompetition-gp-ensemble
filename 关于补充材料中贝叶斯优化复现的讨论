我们在尝试在其他系统复现代码的时候，发现一个问题，即补充材料内，基于贝叶斯优化生成weighted kernel的算法在不同的电脑或者系统（我们尝试了几个不同的系统）出来的结果均不一样。
因为我们现在已经没有评测机会，我们也不知道得分会更高还是更低。因此，我们在这里展示我们对贝叶斯算法的结果不一致的分析以及我们是如何复现的。


1. 为什么贝叶斯优化的结果会不一致。

我们使用的包是bayesian-optimization. 里面会调用scikit-learn的GP算法模块，scipy的L-BFGS最小化算法。理论上，不同的scikit-learn版本或者scipy版本，或者其他python环境中不同的随机数种子都会
导致不一样的优化结果。另外，我们在尝试搭建新环境的时候，发现即使这些库的版本一样，贝叶斯优化的结果依然不一致。最后我们定位到是哪怕一样的L-BFGS代码，算法的计算结果输出会不同。
在尝试了很多种可能后，我们发现不同的mkl库或者numpy可能会导致会导致计算结果出现差异。在更换了不同的mkl以及numpy库版本后，贝叶斯优化的结果会不同。

2. 如何避免这样的现象。

为了达到比较好的复现效果：

使用如下配置:

python=3.8.8
mkl=2021.2
numpy=1.21.5
mkl_fft=1.3.0
mkl_random=1.2.1
mkl-service=2.3.0
scipy==1.4.1

注意，其中部分的包之间因为兼容性问题可能无法一次性安装， 笔者找到了一个可行的路子


我们使用的是MacBook Pro (16-inch, 2019), i7, big Sur系统, 安装好anaconda

在python中启动新环境 为了保证优化库的一致性: 
conda create -n cvpr_challenge -c anaconda python=3.8.8 numpy mkl=2021.2 mkl_fft=1.3.0 mkl_random=1.2.1 mkl-service=2.3.0

然后
pip install scipy==1.4.1
pip install numpy==1.21.5
pip install scikit-learn==0.24.1
pip install jupyter notebook
pip install 或者bayesian_optimization等。

注意：经过反复尝试 如果版本不一致可能会出现不一致的结果。


Example:

负面例子
假设我们用另外一种方式启动新环境 conda create -n cvpr6 python=3.8.8 numpy mkl=2021.4
执行065_finder.ipynb 第一次循环寻参的结果
0.7653   |  0.1      |  0.1      |  1.031    |  1.5      |  1.5      |  0.1      |  0.6284   |  1.5      |  0.1665   |  0.1      |  0.1      |  0.3005   |  0.1      |  0.1      |  1.5      |  0.1      |  0.1      |  0.913    |  1.217    |  0.9525   |  1.13     |  1.275    |  0.1      |  0.1

正面例子
这里是按照流程
执行065_finder.ipynb 第一次循环寻参的结果
0.7653   |  0.1      |  0.1      |  1.052    |  1.5      |  1.5      |  0.1      |  0.6299   |  1.5      |  0.1787   |  0.1      |  0.1      |  0.298    |  0.1      |  0.1      |  1.5      |  0.1      |  0.1      |  0.9111   |  1.222    |  0.9512   |  1.141    |  1.274    |  0.1      |  0.1

可以看到，不同的mkl配置下，第一次循环下寻参的结果就已经改变。
