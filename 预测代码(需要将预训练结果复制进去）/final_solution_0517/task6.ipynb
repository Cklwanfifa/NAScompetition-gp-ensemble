{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0] 100\n"
     ]
    }
   ],
   "source": [
    "#有一些严重的Bug被发现：需要做一个bug-fix版本的提交\n",
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_1:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0]\n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0, 1]\n",
    "            \n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_1 = Preprocessing_1()\n",
    "train_list, arch_list_train_1 = processor_1.process_x(train_data)\n",
    "n_feature = len(arch_list_train_1[0])\n",
    "print(arch_list_train_1[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] 100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_2:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            '''\n",
    "            if i == 0:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            '''\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1, 0]\n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_2 = Preprocessing_2()\n",
    "train_list, arch_list_train_2 = processor_2.process_x(train_data)\n",
    "n_feature = len(arch_list_train_2[0])\n",
    "print(arch_list_train_2[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0] 110\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_3:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            '''\n",
    "            if i == 0:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            '''\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                '''\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0]\n",
    "                '''\n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0, 1]\n",
    "            \n",
    "\n",
    "\n",
    "            if i % 3 == 0 and i != 0 and i <= 30:\n",
    "                tmps = ts\n",
    "                if tmps == '11':\n",
    "                    tp = [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '12':\n",
    "                    tp = [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "                \n",
    "                elif tmps == '13':\n",
    "                    tp = [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '21':\n",
    "                    tp = [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '22':\n",
    "                    tp = [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '23':\n",
    "                    tp = [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '31':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "                elif tmps == '32':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "                    \n",
    "                elif tmps == '33':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "            \n",
    "                temp_arch = temp_arch + tp\n",
    "                ts = ''\n",
    "\n",
    "\n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_3 = Preprocessing_3()\n",
    "train_list, arch_list_train_3 = processor_3.process_x(train_data)\n",
    "n_feature = len(arch_list_train_3[0])\n",
    "print(arch_list_train_3[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0] 190\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_4:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            '''\n",
    "            if i == 0:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            '''\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                \n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0]\n",
    "                \n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0, 1]\n",
    "            \n",
    "\n",
    "\n",
    "            if i % 3 == 0 and i != 0 and i <= 30:\n",
    "                tmps = ts\n",
    "                if tmps == '11':\n",
    "                    tp = [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '12':\n",
    "                    tp = [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "                \n",
    "                elif tmps == '13':\n",
    "                    tp = [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '21':\n",
    "                    tp = [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '22':\n",
    "                    tp = [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '23':\n",
    "                    tp = [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '31':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "                elif tmps == '32':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "                    \n",
    "                elif tmps == '33':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "            \n",
    "                temp_arch = temp_arch + tp\n",
    "                ts = ''\n",
    "\n",
    "\n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_4 = Preprocessing_4()\n",
    "train_list, arch_list_train_4 = processor_4.process_x(train_data)\n",
    "n_feature = len(arch_list_train_4[0])\n",
    "print(arch_list_train_4[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] 190\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from Preprocessing import Preprocessing, Label_Transformer\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "with open('CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Preprocessing_5:\n",
    "    def __init__(self):\n",
    "        self.arch_record = []\n",
    "\n",
    "    def convert_x(self, arch_str):\n",
    "        temp_arch = []\n",
    "        total_1 = 0\n",
    "        total_2 = 0\n",
    "        ts = ''\n",
    "        for i in range(len(arch_str)):\n",
    "            '''\n",
    "            if i == 0:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "            '''\n",
    "            if i % 3 != 0 and i != 0 and i <= 30:\n",
    "                elm = arch_str[i]\n",
    "                ts = ts + elm\n",
    "                \n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 1]\n",
    "                \n",
    "            \n",
    "            elif i % 3 != 0 and i != 0 and i > 30:\n",
    "                elm = arch_str[i]\n",
    "                if elm == 'l' or elm == '1':\n",
    "                    temp_arch = temp_arch + [1, 0, 0, 0, 0]\n",
    "                elif elm == 'j' or elm == '2':\n",
    "                    temp_arch = temp_arch + [0, 1, 0, 0, 0]\n",
    "                elif elm == 'k' or elm == '3':\n",
    "                    temp_arch = temp_arch + [0, 0, 1, 0, 0]\n",
    "                else:\n",
    "                    temp_arch = temp_arch + [0, 0, 0, 0, 0]\n",
    "            \n",
    "\n",
    "\n",
    "            if i % 3 == 0 and i != 0 and i <= 30:\n",
    "                tmps = ts\n",
    "                if tmps == '11':\n",
    "                    tp = [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '12':\n",
    "                    tp = [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "                \n",
    "                elif tmps == '13':\n",
    "                    tp = [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '21':\n",
    "                    tp = [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '22':\n",
    "                    tp = [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "                    \n",
    "                elif tmps == '23':\n",
    "                    tp = [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "                elif tmps == '31':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "                elif tmps == '32':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "                    \n",
    "                elif tmps == '33':\n",
    "                    tp = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "            \n",
    "                temp_arch = temp_arch + tp\n",
    "                ts = ''\n",
    "\n",
    "\n",
    "\n",
    "        return temp_arch\n",
    "    \n",
    "    def process_x(self, train_data):\n",
    "        train_list = [[], [], [], [], [], [], [], []]\n",
    "        arch_list_train = []\n",
    "        name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "        for key in train_data.keys():\n",
    "            for idx, name in enumerate(name_list):\n",
    "                train_list[idx].append(train_data[key][name])\n",
    "            arch_list_train.append(self.convert_x(train_data[key]['arch']))\n",
    "\n",
    "        return train_list, arch_list_train\n",
    "\n",
    "processor_5 = Preprocessing_5()\n",
    "train_list, arch_list_train_5 = processor_5.process_x(train_data)\n",
    "n_feature = len(arch_list_train_5[0])\n",
    "print(arch_list_train_5[0], n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2021  PaddlePaddle Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import numba as nb\n",
    "import itertools\n",
    "\n",
    "nw = 97\n",
    "weights = [1] * 16\n",
    "n_w = len(weights)\n",
    "w_96 = np.array(weights + [1 for x in range(96 - n_w)])\n",
    "w_97 = np.array(weights + [1 for x in range(97 - n_w)])\n",
    "\n",
    "\n",
    "\n",
    "__all__ = [\"GPNAS\"]\n",
    "\n",
    "\n",
    "def get_correlation(mat1, mat2, task):\n",
    "    mat_diff = np.abs(np.array(mat1) - np.array(mat2))\n",
    "    if np.sum(mat_diff) == 0:\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "    diffs = np.dot(mat_diff, mat_diff)\n",
    "    k2 = 1\n",
    "    k1 = 1 * np.exp(-np.sqrt(diffs) / 22)\n",
    "    #k1 = np.exp(-np.log2(diffs) / 24)\n",
    "    #return k1\n",
    "    return k1 * k2\n",
    "\n",
    "\n",
    "def get_cor_mat_joint(X, X_train, task):\n",
    "    X = np.array(X)\n",
    "    X_train = np.array(X_train)\n",
    "    l_c = X.shape[0]\n",
    "    l_r = X_train.shape[0]\n",
    "    \n",
    "    '''\n",
    "    cor_mat = []\n",
    "\n",
    "    for c_idx in range(l_c):\n",
    "        col = []\n",
    "        c_mat = X[c_idx].copy()\n",
    "\n",
    "        for r_idx in range(l_r):\n",
    "            r_mat = X_train[r_idx].copy()\n",
    "            temp_cor = get_correlation(c_mat, r_mat)\n",
    "            col.append(temp_cor)\n",
    "        cor_mat.append(col)\n",
    "    '''\n",
    "    cor_mat = np.array([get_correlation(c_mat, r_mat, task) for c_mat in X for r_mat in X_train]).reshape((l_c, l_r))\n",
    "\n",
    "    return np.mat(cor_mat)\n",
    "\n",
    "\n",
    "\n",
    "class GPNAS(object):\n",
    "    \"\"\"\n",
    "    GPNAS(Gaussian Process based Neural Architecture Search) is a neural architecture search algorithm.\n",
    "    We model the correlation between architectue and performance from a Bayesian perspective. Specifically, by introducing a novel Gaussian Process based\n",
    "    NAS (GP-NAS) method, the correlations are modeled by the kernel function and mean function. The kernel function is also learnable to enable adaptive modeling for complex\n",
    "    correlations in different search spaces. Furthermore, by in-corporating a mutual information based sampling method, we can theoretically ensure the high-performance\n",
    "    architecture with only a small set of samples. After addressing these problems, training GP-NAS once enables direct performance prediction of any architecture in different\n",
    "    scenarios and may obtain efficient networks for different deployment platforms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c_flag=2, m_flag=2):\n",
    "\n",
    "        #self.hp_mat = 0.0000001\n",
    "        #self.hp_cov = 0.01\n",
    "        self.hp_mat = 0.01\n",
    "        self.hp_cov = 0.05\n",
    "        self.cov_w = None\n",
    "        self.w = None\n",
    "        self.c_flag = c_flag\n",
    "        self.m_flag = m_flag\n",
    "    \n",
    "    def set_task(self, task):\n",
    "        self.task = task\n",
    "        \n",
    "    def set_weight(self, weight):\n",
    "        self.weight = weight\n",
    "\n",
    "    \n",
    "    def _get_corelation(self, mat1, mat2):\n",
    "        \"\"\"\n",
    "        give two typical kernel function\n",
    "\n",
    "        Auto kernel hyperparameters estimation to be updated\n",
    "        \"\"\"\n",
    "        '''\n",
    "        mat_diff = abs(mat1 - mat2)\n",
    "        \n",
    "        \n",
    "        mat_diff = mat1 - mat2\n",
    "        ker = np.zeros(int(len(mat1) / 4))\n",
    "\n",
    "        for i in range(int(len(mat1) / 4)):\n",
    "            part = np.array(mat_diff[i*4:(i+1) * 4])\n",
    "            diffs = np.where(part!= 0)[0]\n",
    "            if len(diffs) != 0:\n",
    "                d = diffs[1] - diffs[0]\n",
    "                ker[i] = d\n",
    "                \n",
    "        mat_diff = ker\n",
    "        \n",
    "                \n",
    "        if self.c_flag == 1:\n",
    "\n",
    "            return 0.5 * np.exp(-np.dot(mat_diff, mat_diff) / 16)\n",
    "\n",
    "        elif self.c_flag == 2:\n",
    "\n",
    "            return 1 * np.exp(-np.sqrt(np.dot(mat_diff, mat_diff)) / 12)\n",
    "        '''\n",
    "        return get_correlation(mat1, mat2, self.task)\n",
    "\n",
    "    def _preprocess_X(self, X):\n",
    "        \"\"\"\n",
    "        preprocess of input feature/ tokens of architecture\n",
    "        more complicated preprocess can be added such as nonlineaer transformation\n",
    "        \"\"\"\n",
    "\n",
    "        X = X.tolist()\n",
    "        p_X = copy.deepcopy(X)\n",
    "\n",
    "        for feature in p_X:\n",
    "            feature.append(1)\n",
    "\n",
    "        return p_X\n",
    "\n",
    "    def _get_cor_mat(self, X):\n",
    "        \"\"\"\n",
    "        get kernel matrix\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        l = X.shape[0]\n",
    "        cor_mat = []\n",
    "\n",
    "        for c_idx in range(l):\n",
    "            col = []\n",
    "            c_mat = X[c_idx].copy()\n",
    "\n",
    "            for r_idx in range(l):\n",
    "                r_mat = X[r_idx].copy()\n",
    "                temp_cor = self._get_corelation(c_mat, r_mat)\n",
    "                col.append(temp_cor)\n",
    "            cor_mat.append(col)\n",
    "\n",
    "        return np.mat(cor_mat)\n",
    "\n",
    "    def _get_cor_mat_joint(self, X, X_train):\n",
    "        \"\"\"\n",
    "        get kernel matrix\n",
    "        \"\"\"\n",
    "        '''\n",
    "        X = np.array(X)\n",
    "        X_train = np.array(X_train)\n",
    "        l_c = X.shape[0]\n",
    "        l_r = X_train.shape[0]\n",
    "        cor_mat = []\n",
    "\n",
    "        for c_idx in range(l_c):\n",
    "            col = []\n",
    "            c_mat = X[c_idx].copy()\n",
    "\n",
    "            for r_idx in range(l_r):\n",
    "                r_mat = X_train[r_idx].copy()\n",
    "                temp_cor = self._get_corelation(c_mat, r_mat)\n",
    "                col.append(temp_cor)\n",
    "            cor_mat.append(col)\n",
    "        '''\n",
    "        res = get_cor_mat_joint(X, X_train, self.task)\n",
    "\n",
    "        return np.mat(res)\n",
    "\n",
    "    def get_predict(self, X):\n",
    "        \"\"\"\n",
    "        get the prediction of network architecture X\n",
    "        \"\"\"\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        #print(X.shape)\n",
    "        #print(X[0])\n",
    "\n",
    "        return X * self.w\n",
    "\n",
    "    def get_predict_jiont(self, X, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        get the prediction of network architecture X based on X_train and Y_train\n",
    "        \"\"\"\n",
    "        #X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        X_train = np.mat(X_train)\n",
    "        Y_train = np.mat(Y_train)\n",
    "        m_X = self.get_predict(X)\n",
    "        m_X_train = self.get_predict(X_train)\n",
    "        mat_train = self._get_cor_mat(X_train)\n",
    "        mat_joint = self._get_cor_mat_joint(X, X_train)\n",
    "\n",
    "        return m_X + mat_joint * np.linalg.inv(mat_train + self.hp_mat * np.eye(\n",
    "            X_train.shape[0])) * (Y_train.T - m_X_train)\n",
    "\n",
    "    def get_initial_mean(self, X, Y):\n",
    "        \"\"\"\n",
    "        get initial mean of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        Y = np.mat(Y)\n",
    "        A = np.linalg.inv(X.T * X + self.hp_mat * np.eye(X.shape[\n",
    "            1]))\n",
    "        B = X.T\n",
    "        C = Y.T\n",
    "        print(f'A,B,C shape is {A.shape}, {B.shape}, {C.shape}')\n",
    "        self.w = np.linalg.inv(X.T * X + self.hp_mat * np.eye(X.shape[\n",
    "            1])) * X.T * Y.T\n",
    "\n",
    "        return self.w \n",
    "\n",
    "    def get_initial_cov(self, X):\n",
    "        \"\"\"\n",
    "        get initial coviarnce matrix of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        self.cov_w = self.hp_cov * np.eye(X.shape[1])\n",
    "\n",
    "        return self.cov_w\n",
    "\n",
    "    def get_posterior_mean(self, X, Y):\n",
    "        \"\"\"\n",
    "        get posterior mean of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)           #特征抽取\n",
    "        X = np.mat(X)                       #X的矩阵化\n",
    "        Y = np.mat(Y)                       #Y的矩阵化\n",
    "        cov_mat = self._get_cor_mat(X)      #获得一个叫做cov_mat的东西\n",
    "        if self.m_flag == 1:\n",
    "            self.w = self.w + self.cov_w * X.T * np.linalg.inv(\n",
    "                np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "                 + X * self.cov_w * X.T + self.hp_mat * np.eye(X.shape[0]))* (Y.T - X * self.w)\n",
    "        else:\n",
    "            a1 = np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "            a2 = np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                        1]))\n",
    "            #print(f'the shape of a1 and a2 is {a1.shape}, {a2.shape}')\n",
    "            tmp = X.T * a1 * X\n",
    "            #print(f'Xshape is {X.shape}, XT shape is {X.T.shape},tmp shape is {tmp.shape}')\n",
    "            A = np.linalg.inv(X.T * a1 * X + a2 + self.hp_mat * np.eye(X.shape[1]))\n",
    "            '''\n",
    "            A = np.linalg.inv(X.T * np.linalg.inv(\n",
    "                cov_mat + self.hp_mat * np.eye(X.shape[0])) * X\n",
    "                + np.linalg.inv(\n",
    "                    self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                        1])) + self.hp_mat * np.eye(X.shape[1]))\n",
    "            '''\n",
    "            b1 = np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "            b2 = np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[1]))\n",
    "            #print(f'b1 shape is {b1.shape}, b2 shape is {b2.shape}')\n",
    "            B = (X.T * b1 * Y.T + b2 * self.w)\n",
    "            #print(f'the shape of A and B is {A.shape}, {B.shape}')\n",
    "            self.w = A * B\n",
    "\n",
    "        return self.w\n",
    "\n",
    "    def get_posterior_cov(self, X, Y):\n",
    "        \"\"\"\n",
    "        get posterior coviarnce matrix of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        Y = np.mat(Y)\n",
    "        cov_mat = self._get_cor_mat(X)\n",
    "        self.cov_mat = np.linalg.inv(\n",
    "            np.linalg.inv(X.T * cov_mat * X + self.hp_mat * np.eye(X.shape[1]))\n",
    "            + np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                1])) + self.hp_mat * np.eye(X.shape[1]))\n",
    "\n",
    "        return self.cov_mat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0402计划\n",
    "## y的处理: 从rank变成分数\n",
    "## 方式：正太化\n",
    "class Label_Transformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_rankdict(self, ranks):\n",
    "        np.random.seed(0)\n",
    "        n = len(ranks)\n",
    "        scores = np.random.normal(0, 1, n)\n",
    "        #scores = np.random.standard_cauchy(n)\n",
    "        temp = scores.argsort()\n",
    "        ranks = np.empty_like(temp)\n",
    "        ranks[temp] = np.arange(len(scores))\n",
    "        ranks = (n - 1) - ranks\n",
    "        rankdict = {}\n",
    "        for i in range(n):\n",
    "            rankdict[ranks[i]] = scores[i]\n",
    "        return rankdict\n",
    "    \n",
    "    def rank_to_score(self, rank_dict, ranks):\n",
    "        res = np.array([rank_dict[x] for x in ranks])\n",
    "        return res\n",
    "    \n",
    "    def rank_to_score_direct(self, ranks):\n",
    "        rank_dict = self.get_rankdict(ranks)\n",
    "        score = self.rank_to_score(rank_dict, ranks)\n",
    "        return score\n",
    "        \n",
    "    \n",
    "    def score_to_rank(self, scores):\n",
    "        scores = np.array(scores)\n",
    "        temp = scores.argsort()\n",
    "        rr = np.empty_like(temp)\n",
    "        rr[temp] = np.arange(len(scores))\n",
    "        rr = rr.max() - rr\n",
    "        return rr\n",
    "            \n",
    "        \n",
    "        \n",
    "label_transformer = Label_Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "\n",
    "gp_list_1 = []\n",
    "gp_list_2 = []\n",
    "gp_list_3 = []\n",
    "gp_list_4 = []\n",
    "gp_list_5 = []\n",
    "\n",
    "\n",
    "\n",
    "Y_score = {}\n",
    "\n",
    "knn_list = []\n",
    "\n",
    "\n",
    "for i in range(len(train_list[:])):\n",
    "    gp_list_1.append(GPNAS(2,2))\n",
    "    gp_list_2.append(GPNAS(2,2))\n",
    "    gp_list_3.append(GPNAS(2,2))\n",
    "    gp_list_4.append(GPNAS(2,2))\n",
    "    gp_list_5.append(GPNAS(2,2))\n",
    "    knn_list.append(KNeighborsRegressor(n_neighbors=20))\n",
    "\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train_1), np.array(train_list[i])\n",
    "    Y_all_k = label_transformer.rank_to_score_direct(Y_all_k)\n",
    "    Y_score[i] = Y_all_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "\n",
    "gp_list_1 = []\n",
    "gp_list_2 = []\n",
    "gp_list_3 = []\n",
    "gp_list_4 = []\n",
    "gp_list_5 = []\n",
    "knn_list = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(train_list[:])):\n",
    "    gp_list_1.append(GPNAS(2,2))\n",
    "    gp_list_2.append(GPNAS(2,2))\n",
    "    gp_list_3.append(GPNAS(2,2))\n",
    "    gp_list_4.append(GPNAS(2,2))\n",
    "    gp_list_5.append(GPNAS(2,2))\n",
    "    knn_list.append(KNeighborsRegressor(n_neighbors=10))\n",
    "\n",
    "\n",
    "train_num = 450\n",
    "Y_score = {}\n",
    "Y_pred_2 = []\n",
    "for i in range(8):\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train_1), np.array(train_list[i])\n",
    "    Y_all_k = label_transformer.rank_to_score_direct(Y_all_k)\n",
    "    Y_score[i] = Y_all_k\n",
    "\n",
    "\n",
    "def train_model(gp_list, index):\n",
    "\n",
    "    for i in tqdm(range(8)):\n",
    "        \n",
    "        if i != this_task:\n",
    "            continue\n",
    "            \n",
    "        if index == 1:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_1), np.array(train_list[i])\n",
    "        elif index == 2:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_2), np.array(train_list[i])\n",
    "        elif index == 3:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_3), np.array(train_list[i])\n",
    "        elif index == 4:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_4), np.array(train_list[i])\n",
    "        elif index == 5:\n",
    "            X_all_k, Y_all_k  = np.array(arch_list_train_5), np.array(train_list[i])\n",
    "            \n",
    "        Y_all_k = Y_score[i]\n",
    "        \n",
    "        \n",
    "        #weight = get_weight(**weight_list[i]['params'])\n",
    "        #gp_list[i].set_task(i)\n",
    "        #gp_list[i].set_weight(weight)\n",
    "        \n",
    "        \n",
    "        gp_list[i].get_initial_mean(X_all_k[0::2],Y_all_k[0::2])\n",
    "        init_cov = gp_list[i].get_initial_cov(X_all_k)\n",
    "        gp_list[i].set_task(i)\n",
    "        gp_list[i].get_posterior_mean(X_all_k,Y_all_k) \n",
    "        if index == 1:\n",
    "            knn_list[i].fit(X_all_k, Y_all_k)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(gp_list_1, 1 )\n",
    "#train_model(gp_list_2, 2 )\n",
    "#train_model(gp_list_3, 3 )\n",
    "#train_model(gp_list_4, 4 )\n",
    "#train_model(gp_list_5, 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ENSEMBLE模型搭建\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import numba as nb\n",
    "import itertools\n",
    "\n",
    "\n",
    "class GPNAS_ensemble(object):\n",
    "\n",
    "    def __init__(self, c_flag, m_flag, gp1, gp2, gp3, gp4, gp5, model_knn, base_rate):\n",
    "\n",
    "        self.hp_mat = 0.0001\n",
    "        self.hp_cov = 0.01\n",
    "        self.cov_w = None\n",
    "        self.w = None\n",
    "        self.c_flag = c_flag\n",
    "        self.m_flag = m_flag\n",
    "        self.gp_1 = gp1\n",
    "        self.gp_2 = gp2\n",
    "        self.gp_3 = gp3\n",
    "        self.gp_4 = gp4\n",
    "        self.gp_5 = gp5\n",
    "        self.knn_model = model_knn\n",
    "        self.base_rate = base_rate\n",
    "        self.default_mode = 1\n",
    "    \n",
    "    def set_task(self, task):\n",
    "        self.task = task\n",
    "\n",
    "    def set_weight(self, weight):\n",
    "        self.weight = weight\n",
    "\n",
    "    \n",
    "    def _get_corelation(self, mat1, mat2):\n",
    "        return get_correlation(mat1, mat2, self.task)\n",
    "\n",
    "    def _preprocess_X(self, X):\n",
    "\n",
    "        X = X.tolist()\n",
    "        p_X = copy.deepcopy(X)\n",
    "\n",
    "        for feature in p_X:\n",
    "            feature.append(1)\n",
    "\n",
    "        return p_X\n",
    "\n",
    "    def _get_cor_mat(self, X):\n",
    "\n",
    "        X = np.array(X)\n",
    "        l = X.shape[0]\n",
    "        cor_mat = []\n",
    "\n",
    "        for c_idx in range(l):\n",
    "            col = []\n",
    "            c_mat = X[c_idx].copy()\n",
    "\n",
    "            for r_idx in range(l):\n",
    "                r_mat = X[r_idx].copy()\n",
    "                temp_cor = self._get_corelation(c_mat, r_mat)\n",
    "                col.append(temp_cor)\n",
    "            cor_mat.append(col)\n",
    "\n",
    "        return np.mat(cor_mat)\n",
    "\n",
    "    def _get_cor_mat_joint(self, X, X_train):\n",
    "\n",
    "        res = get_cor_mat_joint(X, X_train, self.task)\n",
    "\n",
    "        return np.mat(res)\n",
    "\n",
    "    def get_predict(self, X1, X2, X3, X4, X5):\n",
    "        \"\"\"\n",
    "        get the prediction of network architecture X\n",
    "        \"\"\"\n",
    "        #X1 = self._preprocess_X(X1)\n",
    "        #X2 = self._preprocess_X(X2)\n",
    "        #X1 = np.mat(X1)\n",
    "        #X2 = np.mat(X2)\n",
    "        res1 = self.gp_1.get_predict(X1)\n",
    "        res2 = self.gp_2.get_predict(X2)\n",
    "        res3 = self.gp_3.get_predict(X3)\n",
    "        res4 = self.gp_4.get_predict(X4)\n",
    "        res5 = self.gp_5.get_predict(X5)\n",
    "        res6 = self.knn_model.predict(X1).reshape(-1,1)\n",
    "        #print(res1.shape, res2.shape, res3.shape)\n",
    "        res = self.base_rate[0] * res1 + self.base_rate[1] * res2 + self.base_rate[2] * res3 + self.base_rate[3] * res4 +self.base_rate[4] * res5 +self.base_rate[5] * res6 \n",
    "        return res\n",
    "\n",
    "    def get_predict_jiont(self, X1, X2, X3, X4, X5, X_train_1, X_train_2, X_train_3, X_train_4, X_train_5, Y_train):\n",
    "        \"\"\"\n",
    "        get the prediction of network architecture X based on X_train and Y_train\n",
    "        \"\"\"\n",
    "        #X = self._preprocess_X(X)\n",
    "        if self.default_mode == 1:\n",
    "            X1 = np.mat(X1)\n",
    "            X_train_1 = np.mat(X_train_1)\n",
    "            Y_train = np.mat(Y_train)\n",
    "            #print(X1.shape)\n",
    "            m_X = self.get_predict(X1, X2, X3, X4, X5)\n",
    "            m_X_train = self.get_predict(X_train_1, X_train_2, X_train_3, X_train_4, X_train_5)\n",
    "            mat_train = self._get_cor_mat(X_train_1)\n",
    "            mat_joint = self._get_cor_mat_joint(X1, X_train_1)\n",
    "\n",
    "            return m_X + mat_joint * np.linalg.inv(mat_train + self.hp_mat * np.eye(\n",
    "                X_train_1.shape[0])) * (Y_train.T - m_X_train)\n",
    "        \n",
    "        elif self.default_mode == 2:\n",
    "            X2 = np.mat(X2)\n",
    "            X_train_2 = np.mat(X_train_2)\n",
    "            Y_train = np.mat(Y_train)\n",
    "            #print(X1.shape)\n",
    "            m_X = self.get_predict(X1, X2, X3, X4, X5)\n",
    "            m_X_train = self.get_predict(X_train_1, X_train_2, X_train_3, X_train_4, X_train_5)\n",
    "            mat_train = self._get_cor_mat(X_train_2)\n",
    "            mat_joint = self._get_cor_mat_joint(X2, X_train_2)\n",
    "\n",
    "            return m_X + mat_joint * np.linalg.inv(mat_train + self.hp_mat * np.eye(\n",
    "                X_train_2.shape[0])) * (Y_train.T - m_X_train)\n",
    "        \n",
    "\n",
    "    def get_initial_mean(self, X, Y):\n",
    "        \"\"\"\n",
    "        get initial mean of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        Y = np.mat(Y)\n",
    "        A = np.linalg.inv(X.T * X + self.hp_mat * np.eye(X.shape[\n",
    "            1]))\n",
    "        B = X.T\n",
    "        C = Y.T\n",
    "        #print(f'A,B,C shape is {A.shape}, {B.shape}, {C.shape}')\n",
    "        self.w = np.linalg.inv(X.T * X + self.hp_mat * np.eye(X.shape[\n",
    "            1])) * X.T * Y.T\n",
    "\n",
    "        return self.w\n",
    "\n",
    "    def get_initial_cov(self, X):\n",
    "        \"\"\"\n",
    "        get initial coviarnce matrix of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        self.cov_w = self.hp_cov * np.eye(X.shape[1])\n",
    "\n",
    "        return self.cov_w\n",
    "\n",
    "    def get_posterior_mean(self, X, Y):\n",
    "        \"\"\"\n",
    "        get posterior mean of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)           #特征抽取\n",
    "        X = np.mat(X)                       #X的矩阵化\n",
    "        Y = np.mat(Y)                       #Y的矩阵化\n",
    "        cov_mat = self._get_cor_mat(X)      #获得一个叫做cov_mat的东西\n",
    "        if self.m_flag == 1:\n",
    "            self.w = self.w + self.cov_w * X.T * np.linalg.inv(\n",
    "                np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "                 + X * self.cov_w * X.T + self.hp_mat * np.eye(X.shape[0]))* (Y.T - X * self.w)\n",
    "        else:\n",
    "            a1 = np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "            a2 = np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                        1]))\n",
    "            #print(f'the shape of a1 and a2 is {a1.shape}, {a2.shape}')\n",
    "            tmp = X.T * a1 * X\n",
    "            #print(f'Xshape is {X.shape}, XT shape is {X.T.shape},tmp shape is {tmp.shape}')\n",
    "            A = np.linalg.inv(X.T * a1 * X + a2 + self.hp_mat * np.eye(X.shape[1]))\n",
    "            b1 = np.linalg.inv(cov_mat + self.hp_mat * np.eye(X.shape[0]))\n",
    "            b2 = np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[1]))\n",
    "            #print(f'b1 shape is {b1.shape}, b2 shape is {b2.shape}')\n",
    "            B = (X.T * b1 * Y.T + b2 * self.w)\n",
    "            #print(f'the shape of A and B is {A.shape}, {B.shape}')\n",
    "            self.w = A * B\n",
    "\n",
    "        return self.w\n",
    "\n",
    "    def get_posterior_cov(self, X, Y):\n",
    "        \"\"\"\n",
    "        get posterior coviarnce matrix of w\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._preprocess_X(X)\n",
    "        X = np.mat(X)\n",
    "        Y = np.mat(Y)\n",
    "        cov_mat = self._get_cor_mat(X)\n",
    "        self.cov_mat = np.linalg.inv(\n",
    "            np.linalg.inv(X.T * cov_mat * X + self.hp_mat * np.eye(X.shape[1]))\n",
    "            + np.linalg.inv(self.cov_w + self.hp_mat * np.eye(X.shape[\n",
    "                1])) + self.hp_mat * np.eye(X.shape[1]))\n",
    "\n",
    "        return self.cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 训练Ensemble模型\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "gp_ensembles = []\n",
    "\n",
    "for i in range(8):\n",
    "    gp1 = gp_list_1[i]\n",
    "    gp2 = gp_list_2[i]\n",
    "    gp3 = gp_list_3[i]\n",
    "    gp4 = gp_list_4[i]\n",
    "    gp5 = gp_list_5[i]\n",
    "    \n",
    "\n",
    "    model_knn = knn_list[i]\n",
    "    if i == 0:\n",
    "        base_rate = [0.3, 0.3, 0, 0, 0, 0.4]\n",
    "    elif i == 5:\n",
    "        base_rate = [0.3,0.5,0.0666,0.0666,0.0666, 0]\n",
    "    else:\n",
    "        base_rate = [0.55,0.3,0.05, 0.05, 0.05, 0]\n",
    "        \n",
    "    gp_ensembles.append(GPNAS_ensemble(2, 2, gp1, gp2, gp3, gp4, gp5, model_knn, base_rate))\n",
    "    gp_ensembles[i].default_mode = 1\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open('./gp_ensemble_task6.pickle', 'wb+') as f:\n",
    "#    pickle.dump(gp_ensembles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./gp_ensemble_task6.pickle', 'rb+') as f:\n",
    "    gp_ensembles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cplfw_rank': 0,\n",
       " 'market1501_rank': 0,\n",
       " 'dukemtmc_rank': 0,\n",
       " 'msmt17_rank': 0,\n",
       " 'veri_rank': 0,\n",
       " 'vehicleid_rank': 0,\n",
       " 'veriwild_rank': 0,\n",
       " 'sop_rank': 0,\n",
       " 'arch': 'j121221121221221311331321121221000000'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#试一下结果吧\n",
    "with open('CVPR_2022_NAS_Track2_test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "test_data['arch99997']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "[0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "test_arch_list_1 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_1.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_1.append(test_arch)\n",
    "print(test_arch_list_1[99499])\n",
    "\n",
    "test_arch_list_2 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_2.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_2.append(test_arch)\n",
    "print(test_arch_list_2[99499])\n",
    "\n",
    "test_arch_list_3 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_3.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_3.append(test_arch)\n",
    "print(test_arch_list_3[99499])\n",
    "\n",
    "test_arch_list_4 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_4.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_4.append(test_arch)\n",
    "print(test_arch_list_4[99499])\n",
    "\n",
    "test_arch_list_5 = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  processor_5.convert_x(test_data[key]['arch'])\n",
    "    test_arch_list_5.append(test_arch)\n",
    "print(test_arch_list_5[99499])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict the rank of: 6\n"
     ]
    }
   ],
   "source": [
    "## Try only task 1\n",
    "name_list = ['veriwild_rank']\n",
    "my_reses = []\n",
    "\n",
    "rank_all = []\n",
    "for task in [6]:\n",
    "    print('Predict the rank of:', task)\n",
    "    Y = Y_score[task]\n",
    "    my_res = gp_ensembles[task].get_predict_jiont(np.array(test_arch_list_1),\n",
    "                                                 np.array(test_arch_list_2),\n",
    "                                                  np.array(test_arch_list_3),\n",
    "                                                  np.array(test_arch_list_4),\n",
    "                                                  np.array(test_arch_list_5),\n",
    "                                                 np.array(arch_list_train_1),\n",
    "                                                 np.array(arch_list_train_2),\n",
    "                                                  np.array(arch_list_train_3),\n",
    "                                                  np.array(arch_list_train_4),\n",
    "                                                  np.array(arch_list_train_5),\n",
    "                                                  Y)\n",
    "    my_reses.append(my_res)\n",
    "    rank_all.append(np.mat(label_transformer.score_to_rank(np.array(my_res.ravel())[0]).reshape(-1,1)))\n",
    "    # fast mode\n",
    "    #rank_all.append(gp_list[task].get_predict(np.array(test_arch_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to save results!\n"
     ]
    }
   ],
   "source": [
    "for idx,key in enumerate(test_data.keys()):\n",
    "    #test_data[key]['cplfw_rank'] = int(rank_all[0][idx][0])\n",
    "    #test_data[key]['market1501_rank'] = int(rank_all[1][idx][0])\n",
    "    #test_data[key]['dukemtmc_rank'] = int(rank_all[2][idx][0])\n",
    "    #test_data[key]['msmt17_rank'] = int(rank_all[3][idx][0])\n",
    "    #test_data[key]['veri_rank'] = int(rank_all[4][idx][0])\n",
    "    #test_data[key]['vehicleid_rank'] = int(rank_all[5][idx][0])\n",
    "    test_data[key]['veriwild_rank'] = int(rank_all[0][idx][0])\n",
    "    #test_data[key]['sop_rank'] = int(rank_all[7][idx][0])\n",
    "print('Ready to save results!')\n",
    "with open('CVPR_2022_NAS_Track2_submit_task6_0510version.json', 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
